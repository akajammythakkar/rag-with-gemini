{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akajammythakkar/rag-with-gemini/blob/main/RAG_with_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FmZxGAfk70a3",
      "metadata": {
        "id": "FmZxGAfk70a3"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip install langchain chromadb pypdf google-generativeai sentence_transformers Ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L5h3_h4C8Q70",
      "metadata": {
        "id": "L5h3_h4C8Q70"
      },
      "source": [
        "#### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
      "metadata": {
        "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
        "from pypdf import PdfReader\n",
        "import google.generativeai as genai\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
      "metadata": {
        "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6"
      },
      "outputs": [],
      "source": [
        "# Create a PdfReader object to read the PDF file\n",
        "reader = PdfReader(\"/content/alphabet annual report.pdf\")\n",
        "\n",
        "# Extract text from each page in the PDF and strip any leading/trailing whitespace\n",
        "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
        "\n",
        "# Filter out any empty strings from the extracted texts\n",
        "pdf_texts = [text for text in pdf_texts if text]\n",
        "\n",
        "# Pretty-print the text from the first page of the PDF\n",
        "pprint(pdf_texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
      "metadata": {
        "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32"
      },
      "outputs": [],
      "source": [
        "# Create a RecursiveCharacterTextSplitter object with specified separators, chunk size, and chunk overlap\n",
        "character_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # List of separators for splitting the text\n",
        "    chunk_size=1000,  # Maximum size of each text chunk\n",
        "    chunk_overlap=0  # Number of characters to overlap between chunks\n",
        ")\n",
        "\n",
        "# Join the extracted PDF texts with '\\n\\n' and split the combined text into chunks\n",
        "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
        "\n",
        "# Pretty-print the text of the 11th chunk (index 10) of the split text\n",
        "pprint(character_split_texts[10])\n",
        "\n",
        "# Print the total number of chunks created\n",
        "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
      "metadata": {
        "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b"
      },
      "outputs": [],
      "source": [
        "# Create a SentenceTransformersTokenTextSplitter object with specified chunk overlap and tokens per chunk\n",
        "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
        "\n",
        "# Initialize an empty list to hold the token-split texts\n",
        "token_split_texts = []\n",
        "\n",
        "# Loop through each chunk in the character-split texts\n",
        "for text in character_split_texts:\n",
        "    # Split the text into smaller chunks using the token splitter and add them to the token_split_texts list\n",
        "    token_split_texts += token_splitter.split_text(text)\n",
        "\n",
        "# Print the wrapped text of the 11th chunk (index 10) of the token-split text\n",
        "pprint(token_split_texts[10])\n",
        "\n",
        "# Print the total number of token-split chunks created\n",
        "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
      "metadata": {
        "id": "c2a13d14-4484-46f0-8e67-277337f9d138"
      },
      "outputs": [],
      "source": [
        "# Create a SentenceTransformerEmbeddingFunction object\n",
        "embedding_function = SentenceTransformerEmbeddingFunction()\n",
        "\n",
        "# Generate embeddings for the 11th chunk (index 10) of the token-split text and print the result\n",
        "print(embedding_function([token_split_texts[10]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
      "metadata": {
        "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87"
      },
      "outputs": [],
      "source": [
        "# Create a ChromaDB client\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Create a new collection in ChromaDB with the name \"Alphabet Annual Report\" and the specified embedding function\n",
        "chroma_collection = chroma_client.create_collection(\"alphabet_annual_report\", embedding_function=embedding_function)\n",
        "\n",
        "# Generate a list of string IDs corresponding to the number of token-split text chunks\n",
        "ids = [str(i) for i in range(len(token_split_texts))]\n",
        "\n",
        "# Add the token-split text chunks to the ChromaDB collection using the generated IDs\n",
        "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
        "\n",
        "# Count and return the number of documents in the ChromaDB collection\n",
        "chroma_collection.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miBZMJi_ApAr",
      "metadata": {
        "id": "miBZMJi_ApAr"
      },
      "outputs": [],
      "source": [
        "# Step 1: Retrieve the API key from user data\n",
        "GEMINI_API_KEY = userdata.get('API_KEY')  # Get API Key from Secrets\n",
        "\n",
        "# Step 2: Configure the GenAI client with the retrieved API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Step 3: Define the generation configuration for the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0.9,       # Controls the randomness of the output (higher values mean more random)\n",
        "    \"top_p\": 1,               # Controls nucleus sampling (1 means no filtering)\n",
        "    \"top_k\": 1,               # Controls the number of highest probability tokens to consider (1 means only the highest)\n",
        "    \"max_output_tokens\": 2048 # Maximum number of tokens in the output\n",
        "}\n",
        "\n",
        "# Step 4: Initialize the generative model with the specified name and configuration\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash\",       # Name of the model\n",
        "    generation_config=generation_config  # Configuration for text generation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3731aa9d-7dec-43e7-adcd-abec44abcd97",
      "metadata": {
        "id": "3731aa9d-7dec-43e7-adcd-abec44abcd97"
      },
      "outputs": [],
      "source": [
        "def rag(query, retrieved_documents):\n",
        "    # Combine the retrieved documents into a single string, separated by double newlines\n",
        "    information = \"\\n\\n\".join(retrieved_documents)\n",
        "\n",
        "    # Create the message for the generative model, providing context and the user's query\n",
        "    messages = [\n",
        "        \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
        "        f\"Question: {query}. \\n Information: {information}\"\n",
        "    ]\n",
        "\n",
        "    # Generate a response using the configured generative model\n",
        "    response = model.generate_content(messages)\n",
        "\n",
        "    # Return the text part of the first candidate's response\n",
        "    return response.candidates[0].content.parts[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K5xH5i-jAm7A",
      "metadata": {
        "id": "K5xH5i-jAm7A"
      },
      "outputs": [],
      "source": [
        "# Step 1: Define the query string\n",
        "query = \"What are some major revenues coming from?\"\n",
        "\n",
        "# Step 2: Query the ChromaDB collection with the specified query string, retrieving the top 3 results\n",
        "results = chroma_collection.query(query_texts=[query], n_results=3)\n",
        "\n",
        "# Step 3: Extract the list of retrieved documents from the query results\n",
        "retrieved_documents = results['documents'][0]\n",
        "\n",
        "# Step 4: Loop through each retrieved document, print the wrapped text, and add a newline for readability\n",
        "for document in retrieved_documents:\n",
        "    pprint(document)\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdde87b-71fc-4f2e-8b40-bcd881e3fe09",
      "metadata": {
        "id": "ffdde87b-71fc-4f2e-8b40-bcd881e3fe09"
      },
      "outputs": [],
      "source": [
        "# Generate the response using the RAG function with the provided query and retrieved documents\n",
        "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
        "\n",
        "# Print the generated response\n",
        "display(Markdown(output))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XVQbjEZ4fBU"
      },
      "id": "4XVQbjEZ4fBU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}